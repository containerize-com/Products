---
title: Apache Spark | Open Source Big Data Processing Framework
description: Apache Spark is a big data processing engine that allows real-time stream processing and in-memory computing that increases the processing speed of the application.
keywords: Apache Spark, big data processing, in memory computing, large scale data processing, in memory data processing, big data processing engine
singlepageh1title: In-Memory Data Processing With Free Big Data Tool
singlepageh2title: Flexible, Lightweight, and faster unified analytics engine for large-scale data processing. Integrated with Hadoop and supports multiple languages.
Shortdescriptionlistingpage: Apache Spark is an open source big data processing engine for large-scale data processing. Increase processing speed of an application with in-memory computing.
linktitle: Apache Spark
Imagetext:  Free Big Data Tool
draft: false
weight: 3
layout: "single"
GithubLink: https://github.com/apache/spark
HomePage_TitleText: Real-ime Data Processing Tool

ListingPage_MenuImage_TitleText: 
ListingPage_MenuImage_AltText: Apache Storm - Big Data Processing
ListingPage_Link_TitleText: Explore Apache Spark

SinglePage_HeaderImage_TitleText: Big Data Processing
SinglePage_HeaderImage_AltText: Big Data Processing
SinglePage_MenuImage_TitleText: Big Data Processing
SinglePage_MenuImage_AltText: Big Data Processing


---
### **Overview**

Apache Spark is a free and open source big data processing engine. It is based on Hadoop MapReduce and is designed for fast computation. Apache Spark extends the Hadoop MapReduce model to allow for more types of computations, such as interactive queries and stream processing, to be performed more efficiently. It supports in-memory cluster computing, which boosts an application's processing speed. Apache Spark handles a variety of workloads including iterative algorithms, interactive queries, and streaming. It comes with out-of-the-box features such as fault tolerance, advanced analytics, lazy evaluation, real-time stream processing, in-memory data processing, and many more.

Over 80 high-level operators are available in Apache Spark, which can be used to create parallel applications. It also includes an API that allows for real-time stream processing. In Apache Spark, all transformations are Lazy in nature. It implies that instead of providing the result immediately, it creates a new RDD from the existing one. As a result, the system's performance is improved. Apache Spark supports multiple languages like Java, R, Scala, Python whereas Hadoop only supports Java language. Apache Spark allows in-memory processing of tasks that increase massive speed. Apache Spark works well with Hadoop's HDFS file system and multiple file-formats like parquet, JSON, CSV, ORC. Hadoop can be easily integrated with Apache Spark either as an input data source or destination.
